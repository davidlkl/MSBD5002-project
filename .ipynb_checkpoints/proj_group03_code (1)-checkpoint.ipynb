{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and to prepare training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_training = pd.read_csv(r\"phase1_training\\volume_training_phase1_table6.csv\", index_col=0)\n",
    "df_volume_testing = pd.read_csv(r\"phase1_test\\volume_test_phase1_table6.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_training.index = pd.to_datetime(df_volume_training.index)\n",
    "df_volume_testing.index = pd.to_datetime(df_volume_testing.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minute_range(start, end, modulo=60):\n",
    "    if start > end:\n",
    "        while start < modulo:\n",
    "            yield start\n",
    "            start += 1\n",
    "        start = 0\n",
    "\n",
    "    while start < end:\n",
    "        yield start\n",
    "        start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_table(df_table):\n",
    "    df_table['Year'] = df_table.index.year\n",
    "    df_table['Month'] = df_table.index.month\n",
    "    df_table['Day'] = df_table.index.day\n",
    "    df_table['Day_of_week'] = df_table.index.dayofweek\n",
    "    df_table['Hour'] = df_table.index.hour\n",
    "    # Modified minute\n",
    "    for i in range(4):\n",
    "        session_1_range = list(minute_range(5*i, 5*i + 20))\n",
    "        session_2_range = list(minute_range(5*i+20, 5*i + 40))\n",
    "        session_3_range = list(minute_range(5*i+40, 5*i))\n",
    "        \n",
    "        time_window_start_label = 'grp_' + str(i+1) + '_time_window_start'\n",
    "        \n",
    "        df_table['Minute'] = (\n",
    "            df_table.index.minute.isin(session_1_range) * session_1_range[0]\n",
    "            + df_table.index.minute.isin(session_2_range) * session_2_range[0]\n",
    "            + df_table.index.minute.isin(session_3_range) * session_3_range[0]\n",
    "        )\n",
    "        df_table[time_window_start_label] = (\n",
    "            pd.to_datetime(df_table[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "        )\n",
    "        df_table.loc[(df_table.index.minute < df_table['Minute']), time_window_start_label] -= datetime.timedelta(minutes=60)\n",
    "        \n",
    "    df_table['Hour'] = df_table.index.hour\n",
    "    df_table['Minute'] = df_table.index.minute\n",
    "    df_table.reset_index(inplace=True)\n",
    "    return df_table\n",
    "\n",
    "df_volume_training = pre_process_table(df_volume_training)\n",
    "df_volume_testing = pre_process_table(df_volume_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_testing['time_window_start'] = df_volume_testing['grp_1_time_window_start']\n",
    "df_volume_testing.drop(df_volume_testing.filter(regex='grp_.*_time_window_start').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing - Imputate the missing vehicle type\n",
    "Only for exit direction, as vehicle type is not recorded for entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_with_vehicle_type = pd.concat([\n",
    "    df_volume_testing[\n",
    "        (~df_volume_testing['vehicle_type'].isna()) &\n",
    "        (df_volume_testing['direction'] == 1)\n",
    "    ],\n",
    "    df_volume_training[\n",
    "        (~df_volume_training['vehicle_type'].isna()) &\n",
    "        (df_volume_training['direction'] == 1)\n",
    "    ]\n",
    "], axis=0).sort_values('grp_1_time_window_start')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>direction</th>\n",
       "      <th>vehicle_model</th>\n",
       "      <th>has_etc</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>time_window_start</th>\n",
       "      <th>grp_1_time_window_start</th>\n",
       "      <th>grp_2_time_window_start</th>\n",
       "      <th>grp_3_time_window_start</th>\n",
       "      <th>grp_4_time_window_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333847</th>\n",
       "      <td>2016-09-19 00:01:55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2016-09-18 23:45:00</td>\n",
       "      <td>2016-09-18 23:50:00</td>\n",
       "      <td>2016-09-18 23:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334073</th>\n",
       "      <td>2016-09-19 00:16:21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2016-09-19 00:05:00</td>\n",
       "      <td>2016-09-19 00:10:00</td>\n",
       "      <td>2016-09-19 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334072</th>\n",
       "      <td>2016-09-19 00:16:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2016-09-19 00:05:00</td>\n",
       "      <td>2016-09-19 00:10:00</td>\n",
       "      <td>2016-09-19 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334070</th>\n",
       "      <td>2016-09-19 00:15:05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2016-09-19 00:05:00</td>\n",
       "      <td>2016-09-19 00:10:00</td>\n",
       "      <td>2016-09-19 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334069</th>\n",
       "      <td>2016-09-19 00:14:35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2016-09-19 00:05:00</td>\n",
       "      <td>2016-09-19 00:10:00</td>\n",
       "      <td>2016-09-18 23:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29436</th>\n",
       "      <td>2016-10-24 16:27:39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-10-24 16:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29437</th>\n",
       "      <td>2016-10-24 16:27:18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-10-24 16:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29438</th>\n",
       "      <td>2016-10-24 16:37:42</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-10-24 16:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29439</th>\n",
       "      <td>2016-10-24 16:47:48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>2016-10-24 16:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29440</th>\n",
       "      <td>2016-10-24 16:48:40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>2016-10-24 16:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225425 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time  tollgate_id  direction  vehicle_model  has_etc  \\\n",
       "333847 2016-09-19 00:01:55            3          1              1        0   \n",
       "334073 2016-09-19 00:16:21            3          1              1        1   \n",
       "334072 2016-09-19 00:16:10            1          1              1        1   \n",
       "334070 2016-09-19 00:15:05            1          1              1        0   \n",
       "334069 2016-09-19 00:14:35            1          1              1        0   \n",
       "...                    ...          ...        ...            ...      ...   \n",
       "29436  2016-10-24 16:27:39            3          1              1        0   \n",
       "29437  2016-10-24 16:27:18            3          1              1        0   \n",
       "29438  2016-10-24 16:37:42            3          1              5        0   \n",
       "29439  2016-10-24 16:47:48            3          1              5        0   \n",
       "29440  2016-10-24 16:48:40            3          1              2        0   \n",
       "\n",
       "        vehicle_type  Year  Month  Day  Day_of_week  Hour  Minute  \\\n",
       "333847           0.0  2016      9   19            0     0       1   \n",
       "334073           0.0  2016      9   19            0     0      16   \n",
       "334072           0.0  2016      9   19            0     0      16   \n",
       "334070           1.0  2016      9   19            0     0      15   \n",
       "334069           0.0  2016      9   19            0     0      14   \n",
       "...              ...   ...    ...  ...          ...   ...     ...   \n",
       "29436            0.0  2016     10   24            0    16      27   \n",
       "29437            0.0  2016     10   24            0    16      27   \n",
       "29438            1.0  2016     10   24            0    16      37   \n",
       "29439            1.0  2016     10   24            0    16      47   \n",
       "29440            1.0  2016     10   24            0    16      48   \n",
       "\n",
       "         time_window_start grp_1_time_window_start grp_2_time_window_start  \\\n",
       "333847                 NaT              2016-09-19     2016-09-18 23:45:00   \n",
       "334073                 NaT              2016-09-19     2016-09-19 00:05:00   \n",
       "334072                 NaT              2016-09-19     2016-09-19 00:05:00   \n",
       "334070                 NaT              2016-09-19     2016-09-19 00:05:00   \n",
       "334069                 NaT              2016-09-19     2016-09-19 00:05:00   \n",
       "...                    ...                     ...                     ...   \n",
       "29436  2016-10-24 16:20:00                     NaT                     NaT   \n",
       "29437  2016-10-24 16:20:00                     NaT                     NaT   \n",
       "29438  2016-10-24 16:20:00                     NaT                     NaT   \n",
       "29439  2016-10-24 16:40:00                     NaT                     NaT   \n",
       "29440  2016-10-24 16:40:00                     NaT                     NaT   \n",
       "\n",
       "       grp_3_time_window_start grp_4_time_window_start  \n",
       "333847     2016-09-18 23:50:00     2016-09-18 23:55:00  \n",
       "334073     2016-09-19 00:10:00     2016-09-19 00:15:00  \n",
       "334072     2016-09-19 00:10:00     2016-09-19 00:15:00  \n",
       "334070     2016-09-19 00:10:00     2016-09-19 00:15:00  \n",
       "334069     2016-09-19 00:10:00     2016-09-18 23:55:00  \n",
       "...                        ...                     ...  \n",
       "29436                      NaT                     NaT  \n",
       "29437                      NaT                     NaT  \n",
       "29438                      NaT                     NaT  \n",
       "29439                      NaT                     NaT  \n",
       "29440                      NaT                     NaT  \n",
       "\n",
       "[225425 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_volume_with_vehicle_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_model  has_etc  vehicle_type\n",
       "1              0        0.0             115051\n",
       "                        1.0              26101\n",
       "               1        0.0              51586\n",
       "                        1.0                141\n",
       "2              0        1.0              12261\n",
       "                        0.0               1306\n",
       "               1        0.0               1592\n",
       "                        1.0                 44\n",
       "3              0        1.0               3830\n",
       "                        0.0                615\n",
       "               1        0.0               1709\n",
       "                        1.0                 92\n",
       "4              0        0.0                767\n",
       "                        1.0                601\n",
       "               1        0.0               2205\n",
       "                        1.0                 10\n",
       "5              0        1.0               6902\n",
       "               1        1.0                 63\n",
       "6              0        1.0                 50\n",
       "7              0        1.0                424\n",
       "               1        1.0                 75\n",
       "Name: vehicle_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputation_training = df_volume_with_vehicle_type[['tollgate_id', 'vehicle_model', 'has_etc', 'Hour', 'vehicle_type']]\n",
    "df_imputation_training_x, df_imputation_training_y = df_imputation_training.iloc[:, :-1], df_imputation_training['vehicle_type']\n",
    "df_imputation_training.groupby(['vehicle_model', 'has_etc'])['vehicle_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Except for case (1, 0), this rule works well\n",
    "base_rule_dict = {\n",
    "    1: [None, 0],\n",
    "    2: [1, 0],\n",
    "    3: [1, 0],\n",
    "    4: [0, 0],\n",
    "    5: [1, 1],\n",
    "    6: [1, 1],\n",
    "    7: [1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicalized rule for case (1, 0)\n",
    "vehicle_type_by_hour_and_tollgate = df_imputation_training[\n",
    "    (df_imputation_training['vehicle_model'] == 1) &\n",
    "    (df_imputation_training['has_etc'] == 0)\n",
    "].groupby(\n",
    "    'Hour'\n",
    ")['vehicle_type'].value_counts()\n",
    "\n",
    "rule_dict_for_1_0 = (\n",
    "    vehicle_type_by_hour_and_tollgate.keys()[0::2]\n",
    "    .to_frame()\n",
    "    .droplevel(1)['vehicle_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hour\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     1.0\n",
       "4     1.0\n",
       "5     1.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "Name: vehicle_type, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_dict_for_1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_based_prediction = df_imputation_training_x[['vehicle_model', 'has_etc', 'Hour']].apply(lambda row: \n",
    "    (               \n",
    "        rule_dict_for_1_0[row[2]]\n",
    "        if (row[0] == 1) and (row[1] == 0)\n",
    "        else\n",
    "        base_rule_dict[row[0]][row[1]]\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753376954641233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rule_based_prediction == df_imputation_training_y).sum() / len(df_imputation_training_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply rule to missing vehicle type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputate(df):\n",
    "    flag_for_imputation =  (df['vehicle_type'].isna() & df['direction'] == 1)\n",
    "    df.loc[flag_for_imputation , 'vehicle_type'] = (\n",
    "        df[flag_for_imputation].apply(\n",
    "        lambda row:\n",
    "              (               \n",
    "                rule_dict_for_1_0[row['Hour']]\n",
    "                if (row['vehicle_model'] == 1) and (row['has_etc'] == 0)\n",
    "                else\n",
    "                base_rule_dict[row['vehicle_model']][row['has_etc']]\n",
    "            ), axis=1\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_volume_training = imputate(df_volume_training)\n",
    "df_volume_testing = imputate(df_volume_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing - Feature generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lagging features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counting_feature(series, label, counting_lists):\n",
    "    count_dict = series.value_counts()\n",
    "    values = [\n",
    "        sum([count_dict.get(c, 0) for c in l]) \n",
    "        for l in counting_lists\n",
    "    ]\n",
    "    labels = [\n",
    "        label + '_' + (\n",
    "            (str(l[0]) + '-' + str(l[-1]))\n",
    "            if len(l) > 1\n",
    "            else\n",
    "            str(l[0])\n",
    "        ) + '_count'\n",
    "        for l in counting_lists\n",
    "    ]\n",
    "    \n",
    "    return values, labels\n",
    "\n",
    "def generate_feature(df, is_entry):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[['vehicle_model', 'has_etc', 'vehicle_type']]\n",
    "    \n",
    "    count = len(df)\n",
    "    \n",
    "    feature_values = []\n",
    "    feature_labels = []\n",
    "    \n",
    "    vehicle_model_count_values, vehicle_model_count_labels = generate_counting_feature(\n",
    "        df['vehicle_model'], 'vehicle_model', [[0,1,2], [3,4,5], [6,7]]\n",
    "    )\n",
    "    \n",
    "    has_etc_count_values, has_etc_count_labels = generate_counting_feature(\n",
    "        df['has_etc'], 'has_etc', [[0], [1]]\n",
    "    )\n",
    "    \n",
    "    vehicle_model_average = df['vehicle_model'].mean()\n",
    "    has_etc_0_model_average = df[df['has_etc']==0]['vehicle_model'].mean()\n",
    "    has_etc_1_model_average = df[df['has_etc']==1]['vehicle_model'].mean()\n",
    "    \n",
    "    vehicle_model_model_average_values = [\n",
    "        vehicle_model_average, has_etc_0_model_average, has_etc_1_model_average\n",
    "    ]\n",
    "    \n",
    "    vehicle_model_model_average_labels = [\n",
    "        'vehicle_model_average', 'has_etc_0_model_average', 'has_etc_1_model_average'\n",
    "    ]\n",
    "    \n",
    "    feature_values += (\n",
    "        vehicle_model_count_values\n",
    "        + has_etc_count_values\n",
    "    )\n",
    "    \n",
    "    feature_labels += (\n",
    "        vehicle_model_count_labels\n",
    "        + has_etc_count_labels\n",
    "    )\n",
    "    \n",
    "    if not is_entry:\n",
    "        vehicle_type_count_values, vehicle_type_count_labels = generate_counting_feature(\n",
    "            df['vehicle_type'] , 'vehicle_type', [[0], [1]]\n",
    "        )\n",
    "        \n",
    "        feature_values += (\n",
    "            vehicle_type_count_values\n",
    "        )\n",
    "        feature_labels += (\n",
    "            vehicle_type_count_labels\n",
    "        )\n",
    "        \n",
    "        \n",
    "    return pd.Series(data=feature_values, index=feature_labels).fillna(0)\n",
    "\n",
    "def concat_df_by_minute_groups(df_list):\n",
    "    time_start_min = df_list[0].index.get_level_values(1).min()\n",
    "    time_start_max = df_list[0].index.get_level_values(1).max()\n",
    "    for i in range(1, 4):\n",
    "        df_list[i] = df_list[i][\n",
    "            (df_list[i].index.get_level_values(1) >= time_start_min) & \n",
    "            (df_list[i].index.get_level_values(1) <= time_start_max)\n",
    "        ]\n",
    "    return pd.concat(df_list).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate lag features for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_start_labels = ['grp_' + str(i+1) +'_time_window_start' for i in range(4)]\n",
    "\n",
    "df_volume_training_entry = df_volume_training[df_volume_training['direction'] == 0]\n",
    "df_volume_training_exit = df_volume_training[df_volume_training['direction'] == 1]\n",
    "\n",
    "df_volume_training_entry_feature_list = []\n",
    "df_volume_training_exit_feature_list = []\n",
    "for label in time_window_start_labels:\n",
    "    df_volume_training_entry_feature_list.append(\n",
    "        df_volume_training_entry.groupby(['tollgate_id', label]).apply(generate_feature, True)\n",
    "    )\n",
    "    df_volume_training_exit_feature_list.append(\n",
    "        df_volume_training_exit.groupby(['tollgate_id', label]).apply(generate_feature, False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_entry_feature = concat_df_by_minute_groups(df_volume_training_entry_feature_list)\n",
    "df_training_exit_feature = concat_df_by_minute_groups(df_volume_training_exit_feature_list)\n",
    "\n",
    "df_training_entry_feature.index.set_names(['tollgate_id', 'time_window_start'], inplace=True)\n",
    "df_training_exit_feature.index.set_names(['tollgate_id', 'time_window_start'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate lag features for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_testing_entry = df_volume_testing[df_volume_testing['direction'] == 0]\n",
    "df_volume_testing_exit = df_volume_testing[df_volume_testing['direction'] == 1]\n",
    "\n",
    "df_testing_entry_feature = df_volume_testing_entry.groupby(['tollgate_id', 'time_window_start']).apply(generate_feature, True)\n",
    "df_testing_exit_feature = df_volume_testing_exit.groupby(['tollgate_id', 'time_window_start']).apply(generate_feature, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the volume to both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_volume(df):\n",
    "    df['volume'] = df['has_etc_0_count'] + df['has_etc_1_count']\n",
    "    return df\n",
    "\n",
    "df_avg_volume_training_entry = adding_volume(df_training_entry_feature)\n",
    "df_avg_volume_training_exit = adding_volume(df_training_exit_feature)\n",
    "\n",
    "df_avg_volume_testing_entry = adding_volume(df_testing_entry_feature)\n",
    "df_avg_volume_testing_exit = adding_volume(df_testing_exit_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 4 minute groups so frequency is 5 minutes instead of 20 minutes\n",
    "dates = df_avg_volume_training_entry.index.get_level_values(1)\n",
    "date_range = pd.date_range(dates.min(), dates.max(), freq=\"5T\")\n",
    "\n",
    "df_avg_volume_training_entry_filled = df_avg_volume_training_entry.groupby(level=0).apply(\n",
    "    lambda df:\n",
    "    df.reset_index(level=0, drop=True)\n",
    "      .reindex(date_range, fill_value=0)\n",
    ")\n",
    "\n",
    "df_avg_volume_training_exit_filled = df_avg_volume_training_exit.groupby(level=0).apply(\n",
    "    lambda df:\n",
    "    df.reset_index(level=0, drop=True)\n",
    "      .reindex(date_range, fill_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>vehicle_model_0-2_count</th>\n",
       "      <th>vehicle_model_3-5_count</th>\n",
       "      <th>vehicle_model_6-7_count</th>\n",
       "      <th>has_etc_0_count</th>\n",
       "      <th>has_etc_1_count</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tollgate_id</th>\n",
       "      <th>time_window_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2016-10-18 06:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18 06:20:00</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18 06:40:00</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18 07:00:00</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18 07:20:00</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>2016-10-24 15:20:00</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-24 15:40:00</th>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>24</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-24 16:00:00</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-24 16:20:00</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-24 16:40:00</th>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>34</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 vehicle_model_0-2_count  \\\n",
       "tollgate_id time_window_start                              \n",
       "1           2016-10-18 06:00:00                       13   \n",
       "            2016-10-18 06:20:00                       17   \n",
       "            2016-10-18 06:40:00                       19   \n",
       "            2016-10-18 07:00:00                       29   \n",
       "            2016-10-18 07:20:00                       28   \n",
       "...                                                  ...   \n",
       "3           2016-10-24 15:20:00                      104   \n",
       "            2016-10-24 15:40:00                      103   \n",
       "            2016-10-24 16:00:00                      114   \n",
       "            2016-10-24 16:20:00                       99   \n",
       "            2016-10-24 16:40:00                      127   \n",
       "\n",
       "                                 vehicle_model_3-5_count  \\\n",
       "tollgate_id time_window_start                              \n",
       "1           2016-10-18 06:00:00                        0   \n",
       "            2016-10-18 06:20:00                        0   \n",
       "            2016-10-18 06:40:00                        2   \n",
       "            2016-10-18 07:00:00                        2   \n",
       "            2016-10-18 07:20:00                        0   \n",
       "...                                                  ...   \n",
       "3           2016-10-24 15:20:00                        1   \n",
       "            2016-10-24 15:40:00                        2   \n",
       "            2016-10-24 16:00:00                        1   \n",
       "            2016-10-24 16:20:00                        1   \n",
       "            2016-10-24 16:40:00                        3   \n",
       "\n",
       "                                 vehicle_model_6-7_count  has_etc_0_count  \\\n",
       "tollgate_id time_window_start                                               \n",
       "1           2016-10-18 06:00:00                        0               11   \n",
       "            2016-10-18 06:20:00                        0               12   \n",
       "            2016-10-18 06:40:00                        0               12   \n",
       "            2016-10-18 07:00:00                        0               18   \n",
       "            2016-10-18 07:20:00                        0               23   \n",
       "...                                                  ...              ...   \n",
       "3           2016-10-24 15:20:00                        0               76   \n",
       "            2016-10-24 15:40:00                        0               81   \n",
       "            2016-10-24 16:00:00                        0               92   \n",
       "            2016-10-24 16:20:00                        0               74   \n",
       "            2016-10-24 16:40:00                        0               96   \n",
       "\n",
       "                                 has_etc_1_count  volume  \n",
       "tollgate_id time_window_start                             \n",
       "1           2016-10-18 06:00:00                2      13  \n",
       "            2016-10-18 06:20:00                5      17  \n",
       "            2016-10-18 06:40:00                9      21  \n",
       "            2016-10-18 07:00:00               13      31  \n",
       "            2016-10-18 07:20:00                5      28  \n",
       "...                                          ...     ...  \n",
       "3           2016-10-24 15:20:00               29     105  \n",
       "            2016-10-24 15:40:00               24     105  \n",
       "            2016-10-24 16:00:00               23     115  \n",
       "            2016-10-24 16:20:00               26     100  \n",
       "            2016-10-24 16:40:00               34     130  \n",
       "\n",
       "[252 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_entry_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lagged_training_df(df, target_window_size=6, lagged_window_size=6, n_minute_grp=4):\n",
    "    df = df.reset_index(level=0, drop=True)\n",
    "    columns = []\n",
    "    columns += ['time_window_start']\n",
    "    for j in range(1, lagged_window_size+1):\n",
    "        columns += (df.columns + '_lag_' + str(j)).tolist()\n",
    "    for k in range(1, target_window_size+1):\n",
    "        columns += ['target_' + str(k)]\n",
    "        \n",
    "    df_values = []\n",
    "    for i in range(len(df) - n_minute_grp * (lagged_window_size + target_window_size) + 1):\n",
    "        window = df.iloc[i:i+lagged_window_size*n_minute_grp:n_minute_grp]\n",
    "        index = df.index[i+lagged_window_size*n_minute_grp]\n",
    "        targets = (\n",
    "            df.iloc[(i+lagged_window_size*n_minute_grp)\n",
    "                    :(i+n_minute_grp*(lagged_window_size+target_window_size))\n",
    "                    :n_minute_grp]['volume']\n",
    "        )\n",
    "        row_values = []\n",
    "        row_values += [index]\n",
    "        for j in range(1, lagged_window_size+1):\n",
    "            row_values += window.iloc[len(window)-j].values.tolist()\n",
    "        row_values += targets.values.tolist()\n",
    "        df_values.append(row_values)\n",
    "    \n",
    "    df = pd.DataFrame(df_values, columns=columns).set_index('time_window_start')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_lagged_testing_df(df, window_size=6):\n",
    "    df = df.reset_index(level=0, drop=True)\n",
    "    columns = []\n",
    "    columns += ['time_window_start']\n",
    "    for j in range(1, lagged_window_size+1):\n",
    "        columns += (df.columns + '_lag_' + str(j)).tolist()\n",
    "        \n",
    "    df_values = []\n",
    "    for i in range(0, len(df) - window_size + 1, window_size):\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        index = df.index[i+window_size-1] + datetime.timedelta(minutes=20)\n",
    "        \n",
    "        row_values = []\n",
    "        row_values += [index]\n",
    "        for j in range(1, window_size+1):\n",
    "            row_values += window.iloc[len(window)-j].values.tolist()\n",
    "\n",
    "        df_values.append(row_values)\n",
    "    \n",
    "    df = pd.DataFrame(df_values, columns=columns).set_index('time_window_start')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_window_size = 6\n",
    "lagged_window_size = 6\n",
    "n_minute_grp = 4\n",
    "\n",
    "df_avg_volume_training_exit_lagged = (\n",
    "    df_avg_volume_training_exit_filled.groupby(level=0).apply(prepare_lagged_training_df, target_window_size, lagged_window_size, n_minute_grp)\n",
    "    .reset_index()\n",
    "    .sort_values(['time_window_start', 'tollgate_id'])\n",
    "    .set_index('time_window_start')\n",
    ")\n",
    "df_avg_volume_training_entry_lagged = (\n",
    "    df_avg_volume_training_entry_filled.groupby(level=0).apply(prepare_lagged_training_df, target_window_size, lagged_window_size, n_minute_grp)\n",
    "    .reset_index()\n",
    "    .sort_values(['time_window_start', 'tollgate_id'])\n",
    "    .set_index('time_window_start')\n",
    ")\n",
    "\n",
    "window_size = 6\n",
    "\n",
    "df_avg_volume_testing_exit_lagged = (\n",
    "    df_avg_volume_testing_exit.groupby(level=0).apply(prepare_lagged_testing_df, window_size)\n",
    "    .reset_index()\n",
    "    .sort_values(['time_window_start', 'tollgate_id'])\n",
    "    .set_index('time_window_start')\n",
    ")\n",
    "\n",
    "df_avg_volume_testing_entry_lagged = (\n",
    "    df_avg_volume_testing_entry.groupby(level=0).apply(prepare_lagged_testing_df, window_size)\n",
    "    .reset_index()\n",
    "    .sort_values(['time_window_start', 'tollgate_id'])\n",
    "    .set_index('time_window_start')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_statistics(df, ):\n",
    "    for column_type in df.filter(regex='_lag_1').columns.str.replace('_lag_1', ''):\n",
    "        df_col = df.filter(regex=column_type+'_lag_\\d')\n",
    "        df[column_type+'_mean'] = df_col.mean(axis=1)\n",
    "        df = df.drop(df.filter(regex=column_type+'_lag_[3-6]').columns, axis=1)\n",
    "    return df\n",
    "\n",
    "df_avg_volume_training_exit_lagged_stat = add_column_statistics(df_avg_volume_training_exit_lagged)\n",
    "df_avg_volume_training_entry_lagged_stat = add_column_statistics(df_avg_volume_training_entry_lagged)\n",
    "df_avg_volume_testing_exit_lagged_stat = add_column_statistics(df_avg_volume_testing_exit_lagged)\n",
    "df_avg_volume_testing_entry_lagged_stat = add_column_statistics(df_avg_volume_testing_entry_lagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_training = pd.read_csv(r\"weather\\weather_July_01_Oct_17_table7.csv\")\n",
    "df_weather_training['date'] = pd.to_datetime(df_weather_training['date'])\n",
    "df_weather_training['date'] += pd.TimedeltaIndex(df_weather_training['hour'], unit='h')\n",
    "df_weather_training = (\n",
    "    df_weather_training\n",
    "    .rename(columns={'date': 'time_window_start'})\n",
    "    .set_index('time_window_start')\n",
    "    .drop('hour', axis=1)\n",
    ")\n",
    "\n",
    "df_weather_testing = pd.read_csv(r\"weather\\weather_Oct_18_Oct_24_table7.csv\")\n",
    "df_weather_testing['date'] = pd.to_datetime(df_weather_testing['date'])\n",
    "df_weather_testing['date'] += pd.TimedeltaIndex(df_weather_testing['hour'], unit='h')\n",
    "df_weather_testing = (\n",
    "    df_weather_testing\n",
    "    .rename(columns={'date': 'time_window_start'})\n",
    "    .set_index('time_window_start')\n",
    "    .drop('hour', axis=1)\n",
    ")\n",
    "df_weather_testing = pd.concat([df_weather_training.iloc[-1:], df_weather_testing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before:\n",
    "# Frequency is set to be 5T due to 4 minute groups\n",
    "\n",
    "df_weather_training_interpolated = (\n",
    "    df_weather_training.reindex(pd.date_range(\n",
    "        df_weather_training.index.min(), df_weather_training.index.max(), freq='5T'\n",
    "    ))\n",
    "    .interpolate(method='linear')\n",
    "    .reindex(pd.date_range(\n",
    "        df_weather_training.index.min(), df_weather_training.index.max()+datetime.timedelta(minutes=160), freq='5T'\n",
    "    ))\n",
    "    .interpolate()\n",
    ")\n",
    "\n",
    "df_weather_testing_interpolated = (\n",
    "    df_weather_testing.reindex(pd.date_range(\n",
    "        df_weather_testing.index.min(), df_weather_testing.index.max(), freq='20T'\n",
    "    ))\n",
    "    .interpolate(method='linear')\n",
    "    .reindex(pd.date_range(\n",
    "        df_weather_testing.index.min(), df_weather_testing.index.max()+datetime.timedelta(minutes=160), freq='20T'\n",
    "    ))\n",
    "    .interpolate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_training_exit_lagged_with_weather_feature = (\n",
    "    df_avg_volume_training_exit_lagged_stat.join(df_weather_training_interpolated)\n",
    ")\n",
    "df_avg_volume_training_entry_lagged_with_weather_feature = (\n",
    "    df_avg_volume_training_entry_lagged_stat.join(df_weather_training_interpolated)\n",
    ")\n",
    "\n",
    "df_avg_volume_testing_exit_lagged_with_weather_feature = (\n",
    "    df_avg_volume_testing_exit_lagged_stat.join(df_weather_testing_interpolated)\n",
    ")\n",
    "df_avg_volume_testing_entry_lagged_with_weather_feature = (\n",
    "    df_avg_volume_testing_entry_lagged_stat.join(df_weather_testing_interpolated)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining_tollgate_info(df, tollgate_id_list, regex_features):\n",
    "\n",
    "    df_tollgate_list = []\n",
    "\n",
    "    for curr_tollgate_id in tollgate_id_list:\n",
    "        df_curr_tollgate = df.loc[\n",
    "            df['tollgate_id'] == curr_tollgate_id,\n",
    "        ]\n",
    "        for i in range(1, len(tollgate_id_list)):\n",
    "            column_list = 'other_tollgate_' + str(i) + '_' + df.filter(regex=regex_features, axis=1).columns\n",
    "            target_tollgate_id = tollgate_id_list[(curr_tollgate_id + i - 1) % 3]\n",
    "            df_target_tollgate = df[\n",
    "                df['tollgate_id'] == target_tollgate_id\n",
    "            ]\n",
    "            df_target_tollgate = df_target_tollgate.filter(regex=regex_features, axis=1)\n",
    "            df_target_tollgate.columns = column_list\n",
    "\n",
    "            df_curr_tollgate = df_curr_tollgate.join(df_target_tollgate)\n",
    "\n",
    "        df_tollgate_list.append(df_curr_tollgate)\n",
    "\n",
    "    return pd.concat(df_tollgate_list)\n",
    "\n",
    "regex = '.*has_etc_[0-1]_count_(lag_1)|.*volume_(mean)'\n",
    "df_avg_volume_training_exit_lagged_with_tollgate_feature = joining_tollgate_info(\n",
    "    df_avg_volume_training_exit_lagged_with_weather_feature,\n",
    "    [1,3],\n",
    "    regex\n",
    ")\n",
    "\n",
    "df_avg_volume_training_entry_lagged_with_tollgate_feature = joining_tollgate_info(\n",
    "    df_avg_volume_training_entry_lagged_with_weather_feature,\n",
    "    [1,2,3],\n",
    "    regex\n",
    ")\n",
    "\n",
    "df_avg_volume_testing_exit_lagged_with_tollgate_feature = joining_tollgate_info(\n",
    "    df_avg_volume_testing_exit_lagged_with_weather_feature,\n",
    "    [1,3],\n",
    "    regex\n",
    ")\n",
    "\n",
    "df_avg_volume_testing_entry_lagged_with_tollgate_feature = joining_tollgate_info(\n",
    "    df_avg_volume_testing_entry_lagged_with_weather_feature,\n",
    "    [1,2,3],\n",
    "    regex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tollgate_id', 'vehicle_model_0-2_count_lag_1',\n",
       "       'vehicle_model_3-5_count_lag_1', 'vehicle_model_6-7_count_lag_1',\n",
       "       'has_etc_0_count_lag_1', 'has_etc_1_count_lag_1', 'volume_lag_1',\n",
       "       'vehicle_model_0-2_count_lag_2', 'vehicle_model_3-5_count_lag_2',\n",
       "       'vehicle_model_6-7_count_lag_2', 'has_etc_0_count_lag_2',\n",
       "       'has_etc_1_count_lag_2', 'volume_lag_2', 'target_1', 'target_2',\n",
       "       'target_3', 'target_4', 'target_5', 'target_6',\n",
       "       'vehicle_model_0-2_count_mean', 'vehicle_model_3-5_count_mean',\n",
       "       'vehicle_model_6-7_count_mean', 'has_etc_0_count_mean',\n",
       "       'has_etc_1_count_mean', 'volume_mean', 'pressure', 'sea_pressure',\n",
       "       'wind_direction', 'wind_speed', 'temperature', 'rel_humidity',\n",
       "       'precipitation', 'other_tollgate_1_has_etc_0_count_lag_1',\n",
       "       'other_tollgate_1_has_etc_1_count_lag_1',\n",
       "       'other_tollgate_1_volume_mean',\n",
       "       'other_tollgate_2_has_etc_0_count_lag_1',\n",
       "       'other_tollgate_2_has_etc_1_count_lag_1',\n",
       "       'other_tollgate_2_volume_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_volume_training_entry_lagged_with_tollgate_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_feature(df):\n",
    "    df['Month'] = df.index.month\n",
    "    df['Day'] = df.index.day\n",
    "    df['Day_of_week'] = df.index.dayofweek\n",
    "    df['Is_weekend'] = df.index.dayofweek.isin([5, 6])\n",
    "    df['Hour'] = df.index.hour\n",
    "    df['Minute'] = df.index.minute\n",
    "    return df\n",
    "\n",
    "df_avg_volume_training_exit_lagged_with_time_feature = add_time_feature(df_avg_volume_training_exit_lagged_with_tollgate_feature)\n",
    "for k in range(1, target_window_size+1):\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature = (\n",
    "        df_avg_volume_training_exit_lagged_with_time_feature.drop(columns=['target_' + str(k)]).assign(**{\n",
    "        'target_'+str(k): df_avg_volume_training_exit_lagged_with_time_feature['target_'+str(k)]\n",
    "        })\n",
    "    )\n",
    "df_avg_volume_training_entry_lagged_with_time_feature = add_time_feature(df_avg_volume_training_entry_lagged_with_tollgate_feature)\n",
    "for k in range(1, target_window_size+1):\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature = (\n",
    "        df_avg_volume_training_entry_lagged_with_time_feature.drop(columns=['target_' + str(k)]).assign(**{\n",
    "        'target_'+str(k): df_avg_volume_training_entry_lagged_with_time_feature['target_'+str(k)]\n",
    "        })\n",
    "    )\n",
    "    \n",
    "df_avg_volume_testing_exit_lagged_with_time_feature = add_time_feature(df_avg_volume_testing_exit_lagged_with_tollgate_feature)\n",
    "df_avg_volume_testing_entry_lagged_with_time_feature = add_time_feature(df_avg_volume_testing_entry_lagged_with_tollgate_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tollgate_id', 'vehicle_model_0-2_count_lag_1',\n",
       "       'vehicle_model_3-5_count_lag_1', 'vehicle_model_6-7_count_lag_1',\n",
       "       'has_etc_0_count_lag_1', 'has_etc_1_count_lag_1', 'volume_lag_1',\n",
       "       'vehicle_model_0-2_count_lag_2', 'vehicle_model_3-5_count_lag_2',\n",
       "       'vehicle_model_6-7_count_lag_2', 'has_etc_0_count_lag_2',\n",
       "       'has_etc_1_count_lag_2', 'volume_lag_2', 'vehicle_model_0-2_count_mean',\n",
       "       'vehicle_model_3-5_count_mean', 'vehicle_model_6-7_count_mean',\n",
       "       'has_etc_0_count_mean', 'has_etc_1_count_mean', 'volume_mean',\n",
       "       'pressure', 'sea_pressure', 'wind_direction', 'wind_speed',\n",
       "       'temperature', 'rel_humidity', 'precipitation',\n",
       "       'other_tollgate_1_has_etc_0_count_lag_1',\n",
       "       'other_tollgate_1_has_etc_1_count_lag_1',\n",
       "       'other_tollgate_1_volume_mean',\n",
       "       'other_tollgate_2_has_etc_0_count_lag_1',\n",
       "       'other_tollgate_2_has_etc_1_count_lag_1',\n",
       "       'other_tollgate_2_volume_mean', 'Month', 'Day', 'Day_of_week',\n",
       "       'Is_weekend', 'Hour', 'Minute', 'target_1', 'target_2', 'target_3',\n",
       "       'target_4', 'target_5', 'target_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_volume_training_entry_lagged_with_time_feature.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction algoritm & Performance - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_extra_data = False\n",
    "only_use_busy_hours = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_training_exit_lagged_with_time_feature = df_avg_volume_training_exit_lagged_with_time_feature.sort_values('tollgate_id').sort_index()\n",
    "df_avg_volume_training_entry_lagged_with_time_feature = df_avg_volume_training_entry_lagged_with_time_feature.sort_values('tollgate_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use data at 0, 20 ,40\n",
    "if not use_extra_data:\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature = (\n",
    "        df_avg_volume_training_exit_lagged_with_time_feature\n",
    "        .groupby('tollgate_id')\n",
    "        .apply(lambda df: df.iloc[::4]).reset_index(level=0, drop=True)\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature = (\n",
    "        df_avg_volume_training_entry_lagged_with_time_feature\n",
    "        .groupby('tollgate_id')\n",
    "        .apply(lambda df: df.iloc[::4]).reset_index(level=0, drop=True)\n",
    "        .sort_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_abnormal_data(df):\n",
    "    is_normal =(\n",
    "        (df.index < datetime.datetime(2016, 10, 1, 0, 0, 0)) |\n",
    "        (df.index > datetime.datetime(2016, 10, 7, 0, 0, 0))\n",
    "    )\n",
    "    return df[is_normal]\n",
    "\n",
    "df_avg_volume_training_exit_lagged_with_time_feature = filter_abnormal_data(df_avg_volume_training_exit_lagged_with_time_feature)\n",
    "df_avg_volume_training_entry_lagged_with_time_feature = filter_abnormal_data(df_avg_volume_training_entry_lagged_with_time_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_use_busy_hours:\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature = df_avg_volume_training_exit_lagged_with_time_feature[\n",
    "        (df_avg_volume_training_exit_lagged_with_time_feature['Hour'].between(7, 8)) |\n",
    "        (df_avg_volume_training_exit_lagged_with_time_feature['Hour'].between(16, 17))\n",
    "    ]\n",
    "    \n",
    "    df_avg_volume_training_entry_lagged_with_time_feature = df_avg_volume_training_entry_lagged_with_time_feature[\n",
    "        (df_avg_volume_training_entry_lagged_with_time_feature['Hour'].between(7, 8)) |\n",
    "        (df_avg_volume_training_entry_lagged_with_time_feature['Hour'].between(16, 17))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_training_exit_lagged_with_time_feature.to_csv('training_set_exit.csv')\n",
    "df_avg_volume_training_entry_lagged_with_time_feature.to_csv('training_set_entry.csv')\n",
    "df_avg_volume_testing_exit_lagged_with_time_feature.to_csv('testing_set_exit.csv')\n",
    "df_avg_volume_testing_entry_lagged_with_time_feature.to_csv('testing_set_entry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, target_window_size=6):\n",
    "    X, Y = df.iloc[:, :-target_window_size], df.iloc[:, -target_window_size:]\n",
    "    split_idx = int(len(X) * 0.75)\n",
    "    x_train, x_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = Y[:split_idx], Y[split_idx:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def fit_model(x_train, y_train, log_transform=False):\n",
    "    model = RandomForestRegressor(n_estimators=500, random_state=0)\n",
    "    if log_transform:\n",
    "        model.fit(x_train, np.log(y_train+1))\n",
    "    else:\n",
    "        model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, x_test, y_test, log_transform=False):\n",
    "    y_test_predict = model.predict(x_test)\n",
    "    if log_transform:\n",
    "        y_test_predict = np.exp(y_test_predict) - 1\n",
    "    print('MAE:')\n",
    "    print(((y_test - y_test_predict).abs()).mean())\n",
    "    print('sMAPE:')\n",
    "    print(((y_test - y_test_predict).abs() / (y_test+y_test_predict) * 2).mean())\n",
    "    print(pd.Series(model.feature_importances_, x_test.columns).sort_values(ascending=False).iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- Direction: Exit\n",
    "- no transform vs log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    8.353540\n",
      "target_2    8.641818\n",
      "target_3    8.976258\n",
      "target_4    9.180740\n",
      "target_5    9.587277\n",
      "target_6    9.891881\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.163928\n",
      "target_2    0.166688\n",
      "target_3    0.174234\n",
      "target_4    0.178898\n",
      "target_5    0.181306\n",
      "target_6    0.183519\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1                     0.310105\n",
      "Hour                                      0.299668\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.143082\n",
      "Minute                                    0.056818\n",
      "Day                                       0.015912\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1     8.498597\n",
      "target_2     8.893205\n",
      "target_3     9.285869\n",
      "target_4     9.322358\n",
      "target_5    10.052363\n",
      "target_6    10.546628\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.167634\n",
      "target_2    0.170134\n",
      "target_3    0.177630\n",
      "target_4    0.179775\n",
      "target_5    0.189180\n",
      "target_6    0.193759\n",
      "dtype: float64\n",
      "Hour                                      0.422792\n",
      "has_etc_0_count_lag_1                     0.298856\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.068387\n",
      "Minute                                    0.046537\n",
      "tollgate_id                               0.017452\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_exit_lagged_with_time_feature, target_window_size)\n",
    "model = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "\n",
    "model_log = fit_model(x_train, y_train, log_transform=True)\n",
    "evaluate_model(model_log, x_test, y_test, log_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    6.773195\n",
      "target_2    7.459591\n",
      "target_3    7.832195\n",
      "target_4    8.196939\n",
      "target_5    8.439244\n",
      "target_6    8.502245\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.255551\n",
      "target_2    0.270800\n",
      "target_3    0.274603\n",
      "target_4    0.283990\n",
      "target_5    0.274949\n",
      "target_6    0.290138\n",
      "dtype: float64\n",
      "volume_lag_1                     0.541350\n",
      "vehicle_model_0-2_count_lag_1    0.140695\n",
      "Hour                             0.108594\n",
      "has_etc_0_count_lag_1            0.041821\n",
      "other_tollgate_2_volume_mean     0.024196\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    6.880608\n",
      "target_2    7.574917\n",
      "target_3    8.011021\n",
      "target_4    8.453198\n",
      "target_5    8.857189\n",
      "target_6    9.346641\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.258660\n",
      "target_2    0.271681\n",
      "target_3    0.277793\n",
      "target_4    0.288330\n",
      "target_5    0.299445\n",
      "target_6    0.309526\n",
      "dtype: float64\n",
      "volume_lag_1                     0.574209\n",
      "vehicle_model_0-2_count_lag_1    0.137558\n",
      "Hour                             0.108225\n",
      "other_tollgate_1_volume_mean     0.022118\n",
      "tollgate_id                      0.018210\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_entry_lagged_with_time_feature, target_window_size)\n",
    "model = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "\n",
    "model_log = fit_model(x_train, y_train, log_transform=True)\n",
    "evaluate_model(model_log, x_test, y_test, log_transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- Direction: Exit\n",
    "- Global vs separate model on tollgate 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    8.353540\n",
      "target_2    8.641818\n",
      "target_3    8.976258\n",
      "target_4    9.180740\n",
      "target_5    9.587277\n",
      "target_6    9.891881\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.163928\n",
      "target_2    0.166688\n",
      "target_3    0.174234\n",
      "target_4    0.178898\n",
      "target_5    0.181306\n",
      "target_6    0.183519\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1                     0.310105\n",
      "Hour                                      0.299668\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.143082\n",
      "Minute                                    0.056818\n",
      "Day                                       0.015912\n",
      "dtype: float64\n",
      "\n",
      "only tollgate 1\n",
      "MAE:\n",
      "target_1    7.719747\n",
      "target_2    7.872005\n",
      "target_3    8.219367\n",
      "target_4    8.548248\n",
      "target_5    9.150112\n",
      "target_6    9.356418\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.145032\n",
      "target_2    0.148269\n",
      "target_3    0.154405\n",
      "target_4    0.160396\n",
      "target_5    0.164050\n",
      "target_6    0.164704\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1                     0.310105\n",
      "Hour                                      0.299668\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.143082\n",
      "Minute                                    0.056818\n",
      "Day                                       0.015912\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1     7.949406\n",
      "target_2     8.399912\n",
      "target_3     8.895202\n",
      "target_4     9.112253\n",
      "target_5    10.259178\n",
      "target_6    10.073367\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.147270\n",
      "target_2    0.153898\n",
      "target_3    0.160114\n",
      "target_4    0.165477\n",
      "target_5    0.180361\n",
      "target_6    0.180682\n",
      "dtype: float64\n",
      "vehicle_type_1_count_mean    0.616900\n",
      "Hour                         0.117893\n",
      "Minute                       0.039468\n",
      "has_etc_0_count_mean         0.035014\n",
      "Day                          0.021233\n",
      "dtype: float64\n",
      "\n",
      "only tollgate 3\n",
      "MAE:\n",
      "target_1     8.987333\n",
      "target_2     9.411630\n",
      "target_3     9.733148\n",
      "target_4     9.813231\n",
      "target_5    10.024443\n",
      "target_6    10.427343\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.182823\n",
      "target_2    0.185108\n",
      "target_3    0.194063\n",
      "target_4    0.197400\n",
      "target_5    0.198562\n",
      "target_6    0.202333\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1                     0.310105\n",
      "Hour                                      0.299668\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.143082\n",
      "Minute                                    0.056818\n",
      "Day                                       0.015912\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1     9.167270\n",
      "target_2     9.659036\n",
      "target_3     9.840623\n",
      "target_4     9.965922\n",
      "target_5    11.126209\n",
      "target_6    11.644720\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.183700\n",
      "target_2    0.188507\n",
      "target_3    0.192800\n",
      "target_4    0.196452\n",
      "target_5    0.212665\n",
      "target_6    0.222040\n",
      "dtype: float64\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.475773\n",
      "Hour                                      0.207051\n",
      "Minute                                    0.047741\n",
      "vehicle_type_1_count_mean                 0.044904\n",
      "other_tollgate_1_volume_mean              0.025271\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_exit_lagged_with_time_feature, target_window_size)\n",
    "model = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "\n",
    "df_avg_volume_training_exit_lagged_with_time_feature_1 = df_avg_volume_training_exit_lagged_with_time_feature[\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature['tollgate_id'] == 1\n",
    "]\n",
    "df_avg_volume_training_exit_lagged_with_time_feature_3 = df_avg_volume_training_exit_lagged_with_time_feature[\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature['tollgate_id'] == 3\n",
    "]\n",
    "print()\n",
    "print('only tollgate 1')\n",
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_exit_lagged_with_time_feature_1, target_window_size)\n",
    "model_1 = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "evaluate_model(model_1, x_test, y_test)\n",
    "print()\n",
    "print('only tollgate 3')\n",
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_exit_lagged_with_time_feature_3, target_window_size)\n",
    "model_3 = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "evaluate_model(model_3, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    6.773195\n",
      "target_2    7.459591\n",
      "target_3    7.832195\n",
      "target_4    8.196939\n",
      "target_5    8.439244\n",
      "target_6    8.502245\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.255551\n",
      "target_2    0.270800\n",
      "target_3    0.274603\n",
      "target_4    0.283990\n",
      "target_5    0.274949\n",
      "target_6    0.290138\n",
      "dtype: float64\n",
      "volume_lag_1                     0.541350\n",
      "vehicle_model_0-2_count_lag_1    0.140695\n",
      "Hour                             0.108594\n",
      "has_etc_0_count_lag_1            0.041821\n",
      "other_tollgate_2_volume_mean     0.024196\n",
      "dtype: float64\n",
      "\n",
      "only tollgate 1\n",
      "MAE:\n",
      "target_1    4.997275\n",
      "target_2    5.658350\n",
      "target_3    5.667723\n",
      "target_4    6.030521\n",
      "target_5    6.289513\n",
      "target_6    6.449139\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.211515\n",
      "target_2    0.229167\n",
      "target_3    0.231513\n",
      "target_4    0.238844\n",
      "target_5    0.248917\n",
      "target_6    0.251472\n",
      "dtype: float64\n",
      "volume_lag_1                     0.541350\n",
      "vehicle_model_0-2_count_lag_1    0.140695\n",
      "Hour                             0.108594\n",
      "has_etc_0_count_lag_1            0.041821\n",
      "other_tollgate_2_volume_mean     0.024196\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    5.244754\n",
      "target_2    5.687869\n",
      "target_3    5.870151\n",
      "target_4    6.093319\n",
      "target_5    6.208350\n",
      "target_6    6.484949\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.214244\n",
      "target_2    0.226510\n",
      "target_3    0.231745\n",
      "target_4    0.237227\n",
      "target_5    0.244002\n",
      "target_6    0.252321\n",
      "dtype: float64\n",
      "volume_lag_1                     0.428588\n",
      "has_etc_0_count_lag_1            0.164397\n",
      "vehicle_model_0-2_count_lag_1    0.129543\n",
      "Hour                             0.053995\n",
      "rel_humidity                     0.033746\n",
      "dtype: float64\n",
      "\n",
      "only tollgate 2\n",
      "MAE:\n",
      "target_1    6.869645\n",
      "target_2    7.433596\n",
      "target_3    7.951854\n",
      "target_4    8.207071\n",
      "target_5    8.376170\n",
      "target_6    8.518355\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.411755\n",
      "target_2    0.426756\n",
      "target_3    0.433716\n",
      "target_4    0.449748\n",
      "target_5    0.405882\n",
      "target_6    0.449235\n",
      "dtype: float64\n",
      "volume_lag_1                     0.541350\n",
      "vehicle_model_0-2_count_lag_1    0.140695\n",
      "Hour                             0.108594\n",
      "has_etc_0_count_lag_1            0.041821\n",
      "other_tollgate_2_volume_mean     0.024196\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    6.617260\n",
      "target_2    7.369255\n",
      "target_3    7.544326\n",
      "target_4    7.742316\n",
      "target_5    8.056345\n",
      "target_6    8.324238\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.408013\n",
      "target_2    0.402881\n",
      "target_3    0.411972\n",
      "target_4    0.429668\n",
      "target_5    0.425480\n",
      "target_6    0.441107\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1            0.388781\n",
      "Hour                             0.189639\n",
      "vehicle_model_0-2_count_lag_1    0.150499\n",
      "volume_lag_1                     0.106734\n",
      "has_etc_0_count_mean             0.011536\n",
      "dtype: float64\n",
      "\n",
      "only tollgate 3\n",
      "MAE:\n",
      "target_1     8.452667\n",
      "target_2     9.286827\n",
      "target_3     9.877007\n",
      "target_4    10.353226\n",
      "target_5    10.652049\n",
      "target_6    10.539241\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.143383\n",
      "target_2    0.156857\n",
      "target_3    0.159740\n",
      "target_4    0.163780\n",
      "target_5    0.173551\n",
      "target_6    0.170094\n",
      "dtype: float64\n",
      "volume_lag_1                     0.541350\n",
      "vehicle_model_0-2_count_lag_1    0.140695\n",
      "Hour                             0.108594\n",
      "has_etc_0_count_lag_1            0.041821\n",
      "other_tollgate_2_volume_mean     0.024196\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1     8.379625\n",
      "target_2     9.022861\n",
      "target_3     9.426404\n",
      "target_4    10.156345\n",
      "target_5    10.451484\n",
      "target_6    10.508024\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.141993\n",
      "target_2    0.150808\n",
      "target_3    0.151679\n",
      "target_4    0.160333\n",
      "target_5    0.166730\n",
      "target_6    0.168599\n",
      "dtype: float64\n",
      "volume_lag_1                     0.615476\n",
      "Hour                             0.205001\n",
      "vehicle_model_0-2_count_lag_1    0.016667\n",
      "has_etc_0_count_mean             0.014319\n",
      "rel_humidity                     0.012510\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_entry_lagged_with_time_feature, target_window_size)\n",
    "model = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "\n",
    "df_avg_volume_training_entry_lagged_with_time_feature_1 = df_avg_volume_training_entry_lagged_with_time_feature[\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature['tollgate_id'] == 1\n",
    "]\n",
    "df_avg_volume_training_entry_lagged_with_time_feature_2 = df_avg_volume_training_entry_lagged_with_time_feature[\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature['tollgate_id'] == 2\n",
    "]\n",
    "df_avg_volume_training_entry_lagged_with_time_feature_3 = df_avg_volume_training_entry_lagged_with_time_feature[\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature['tollgate_id'] == 3\n",
    "]\n",
    "print()\n",
    "print('only tollgate 1')\n",
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_entry_lagged_with_time_feature_1, target_window_size)\n",
    "model_1 = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "evaluate_model(model_1, x_test, y_test)\n",
    "print()\n",
    "\n",
    "print('only tollgate 2')\n",
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_entry_lagged_with_time_feature_2, target_window_size)\n",
    "model_2 = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "evaluate_model(model_2, x_test, y_test)\n",
    "print()\n",
    "\n",
    "print('only tollgate 3')\n",
    "x_train, y_train, x_test, y_test = train_test_split(df_avg_volume_training_entry_lagged_with_time_feature_3, target_window_size)\n",
    "model_3 = fit_model(x_train, y_train)\n",
    "evaluate_model(model, x_test, y_test)\n",
    "evaluate_model(model_3, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clues from training\n",
    "- For exit direction: Train global model is better\n",
    "- For entry direction: Train global model is better, except tollgate 1\n",
    "\n",
    "- Log transformed model has better performance if MAPE is used as evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train global models for exit and entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    2.891739\n",
      "target_2    2.989486\n",
      "target_3    3.064178\n",
      "target_4    3.074831\n",
      "target_5    3.190230\n",
      "target_6    3.261313\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.072615\n",
      "target_2    0.074158\n",
      "target_3    0.074922\n",
      "target_4    0.074405\n",
      "target_5    0.077426\n",
      "target_6    0.078444\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1                     0.334720\n",
      "Hour                                      0.308003\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.116536\n",
      "Minute                                    0.057273\n",
      "vehicle_type_0_count_lag_1                0.016638\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train = df_avg_volume_training_exit_lagged_with_time_feature.iloc[:, :-target_window_size]\n",
    "y_train = df_avg_volume_training_exit_lagged_with_time_feature.iloc[:, -target_window_size:]\n",
    "model_exit = fit_model(x_train, y_train, log_transform=False)\n",
    "evaluate_model(model_exit, x_train, y_train, log_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    2.523897\n",
      "target_2    2.629417\n",
      "target_3    2.689509\n",
      "target_4    2.734358\n",
      "target_5    2.844729\n",
      "target_6    2.882042\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.171758\n",
      "target_2    0.170005\n",
      "target_3    0.171794\n",
      "target_4    0.175957\n",
      "target_5    0.177752\n",
      "target_6    0.177076\n",
      "dtype: float64\n",
      "volume_lag_1                     0.511028\n",
      "vehicle_model_0-2_count_lag_1    0.169984\n",
      "Hour                             0.123375\n",
      "has_etc_0_count_lag_1            0.031535\n",
      "other_tollgate_2_volume_mean     0.023423\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train = df_avg_volume_training_entry_lagged_with_time_feature.iloc[:, :-target_window_size]\n",
    "y_train = df_avg_volume_training_entry_lagged_with_time_feature.iloc[:, -target_window_size:]\n",
    "model_entry = fit_model(x_train, y_train, log_transform=False)\n",
    "evaluate_model(model_entry, x_train, y_train, log_transform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train separate model by tollgate for exit and entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    2.874083\n",
      "target_2    3.033024\n",
      "target_3    3.088145\n",
      "target_4    3.064670\n",
      "target_5    3.273468\n",
      "target_6    3.317188\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.067704\n",
      "target_2    0.070318\n",
      "target_3    0.071544\n",
      "target_4    0.070725\n",
      "target_5    0.076968\n",
      "target_6    0.079118\n",
      "dtype: float64\n",
      "vehicle_type_1_count_mean    0.614747\n",
      "Hour                         0.128520\n",
      "Minute                       0.043848\n",
      "has_etc_0_count_mean         0.027928\n",
      "Day                          0.016369\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    3.047491\n",
      "target_2    3.287783\n",
      "target_3    3.328004\n",
      "target_4    3.360141\n",
      "target_5    3.537377\n",
      "target_6    3.587631\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.080315\n",
      "target_2    0.085129\n",
      "target_3    0.084096\n",
      "target_4    0.083999\n",
      "target_5    0.092192\n",
      "target_6    0.094992\n",
      "dtype: float64\n",
      "other_tollgate_1_has_etc_0_count_lag_1    0.479682\n",
      "Hour                                      0.208488\n",
      "Minute                                    0.051469\n",
      "vehicle_type_1_count_mean                 0.049730\n",
      "has_etc_1_count_mean                      0.024679\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model_exit_list = []\n",
    "for tollgate_id in [1, 3]:\n",
    "    df_avg_volume_training_exit_lagged_with_time_feature_by_tollgate = df_avg_volume_training_exit_lagged_with_time_feature[\n",
    "        df_avg_volume_training_exit_lagged_with_time_feature['tollgate_id'] == tollgate_id\n",
    "    ]\n",
    "    # Train model for direction entry by tollgate\n",
    "    x_train = df_avg_volume_training_exit_lagged_with_time_feature_by_tollgate.iloc[:, :-target_window_size]\n",
    "    y_train = df_avg_volume_training_exit_lagged_with_time_feature_by_tollgate.iloc[:, -target_window_size:]\n",
    "    model_exit_by_tollgate = fit_model(x_train, y_train, log_transform=False)\n",
    "    evaluate_model(model_exit_by_tollgate, x_train, y_train, log_transform=False)\n",
    "    model_exit_list.append(model_exit_by_tollgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "target_1    2.141819\n",
      "target_2    2.225486\n",
      "target_3    2.259786\n",
      "target_4    2.313055\n",
      "target_5    2.349688\n",
      "target_6    2.360830\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.091651\n",
      "target_2    0.095104\n",
      "target_3    0.095540\n",
      "target_4    0.097829\n",
      "target_5    0.100622\n",
      "target_6    0.101510\n",
      "dtype: float64\n",
      "volume_lag_1                     0.451870\n",
      "has_etc_0_count_lag_1            0.168112\n",
      "vehicle_model_0-2_count_lag_1    0.076204\n",
      "Hour                             0.072051\n",
      "rel_humidity                     0.028616\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    2.262078\n",
      "target_2    2.348062\n",
      "target_3    2.395811\n",
      "target_4    2.461890\n",
      "target_5    2.528205\n",
      "target_6    2.551149\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.354126\n",
      "target_2    0.336926\n",
      "target_3    0.331272\n",
      "target_4    0.342133\n",
      "target_5    0.354583\n",
      "target_6    0.357816\n",
      "dtype: float64\n",
      "has_etc_0_count_lag_1            0.290104\n",
      "Hour                             0.211034\n",
      "volume_lag_1                     0.205741\n",
      "vehicle_model_0-2_count_lag_1    0.151916\n",
      "has_etc_0_count_mean             0.021469\n",
      "dtype: float64\n",
      "MAE:\n",
      "target_1    3.015708\n",
      "target_2    3.020280\n",
      "target_3    3.021425\n",
      "target_4    3.072850\n",
      "target_5    3.167984\n",
      "target_6    3.189083\n",
      "dtype: float64\n",
      "sMAPE:\n",
      "target_1    0.058411\n",
      "target_2    0.058725\n",
      "target_3    0.058626\n",
      "target_4    0.058667\n",
      "target_5    0.061163\n",
      "target_6    0.060860\n",
      "dtype: float64\n",
      "volume_lag_1                     0.610781\n",
      "Hour                             0.234788\n",
      "has_etc_1_count_lag_1            0.014886\n",
      "vehicle_model_0-2_count_lag_1    0.014227\n",
      "has_etc_0_count_mean             0.012888\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model_entry_list = []\n",
    "for tollgate_id in range(1, 4):\n",
    "    df_avg_volume_training_entry_lagged_with_time_feature_by_tollgate = df_avg_volume_training_entry_lagged_with_time_feature[\n",
    "        df_avg_volume_training_entry_lagged_with_time_feature['tollgate_id'] == tollgate_id\n",
    "    ]\n",
    "    # Train model for direction entry by tollgate\n",
    "    x_train = df_avg_volume_training_entry_lagged_with_time_feature_by_tollgate.iloc[:, :-target_window_size]\n",
    "    y_train = df_avg_volume_training_entry_lagged_with_time_feature_by_tollgate.iloc[:, -target_window_size:]\n",
    "    model_entry_by_tollgate = fit_model(x_train, y_train, log_transform=False)\n",
    "    evaluate_model(model_entry_by_tollgate, x_train, y_train, log_transform=False)\n",
    "    model_entry_list.append(model_entry_by_tollgate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare testing set truth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing_set_truth = pd.read_csv(r\"phase2\\volume(table 6)_training2.csv\", index_col=0)\n",
    "df_testing_set_truth.index = pd.to_datetime(df_testing_set_truth.index)\n",
    "df_testing_set_truth = (\n",
    "    df_testing_set_truth\n",
    "    .reset_index()\n",
    "    .sort_values(['tollgate_id', 'direction', 'time'])\n",
    "    .set_index(['tollgate_id', 'direction', 'time'])\n",
    ")\n",
    "df_testing_set_truth = (\n",
    "    df_testing_set_truth\n",
    "    .groupby(level=[0,1])\n",
    "    .apply(\n",
    "        lambda df: df\n",
    "        .reset_index(level=[0,1], drop=True)['has_etc']\n",
    "        .resample('20T')\n",
    "        .count()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(prediction, truth):\n",
    "    return np.abs(prediction - truth) / truth\n",
    "\n",
    "def predict_test_set(df, df_testing_set_truth, global_model, \n",
    "                                        local_model_list, tollgate_id_list, log_transform=False, is_exit=False):\n",
    "\n",
    "    results_entry = []\n",
    "    \n",
    "    global_predictions = []\n",
    "    local_predictions = []\n",
    "    \n",
    "    truth_values = []\n",
    "    for idx, tollgate_id in enumerate(tollgate_id_list):\n",
    "        local_model = local_model_list[idx]\n",
    "        \n",
    "        df_by_tollgate = df[df['tollgate_id'] == tollgate_id]\n",
    "        x_test = df_by_tollgate\n",
    "        \n",
    "        if log_transform:\n",
    "            local_prediction = np.exp(local_model.predict(x_test)) - 1\n",
    "            global_prediction = np.exp(global_model.predict(x_test)) - 1\n",
    "        else:\n",
    "            local_prediction = local_model.predict(x_test)\n",
    "            global_prediction = global_model.predict(x_test)\n",
    "        \n",
    "        local_predictions.append(local_prediction)\n",
    "        global_predictions.append(global_prediction)\n",
    "        \n",
    "        time_window_start_index = df_by_tollgate.index\n",
    "        truth_values_by_tollgate = []\n",
    "\n",
    "        for time_window_start in time_window_start_index:\n",
    "            predict_time_window_starts = pd.date_range(\n",
    "                time_window_start, time_window_start + datetime.timedelta(minutes=(window_size-1)*20), freq='20T'\n",
    "            )\n",
    "\n",
    "            truth_values_by_tollgate.append(df_testing_set_truth.loc[tollgate_id, (is_exit*1), predict_time_window_starts].values)\n",
    "        \n",
    "        truth_values.append(truth_values_by_tollgate)\n",
    "        \n",
    "    return np.array(global_predictions), np.array(local_predictions), np.array(truth_values)\n",
    "\n",
    "\n",
    "global_prediction_entry, local_prediction_entry, truth_entry = predict_test_set(\n",
    "    df_avg_volume_testing_entry_lagged_with_time_feature,\n",
    "    df_testing_set_truth,\n",
    "    model_entry,\n",
    "    model_entry_list,\n",
    "    [1,2,3],\n",
    "    log_transform=False,\n",
    "    is_exit=False\n",
    ")       \n",
    "\n",
    "global_prediction_exit, local_prediction_exit, truth_exit = predict_test_set(\n",
    "    df_avg_volume_testing_exit_lagged_with_time_feature,\n",
    "    df_testing_set_truth,\n",
    "    model_exit,\n",
    "    model_exit_list,\n",
    "    [1,3],\n",
    "    log_transform=False,\n",
    "    is_exit=True\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_exit = 0.5*global_prediction_exit+0.5*local_prediction_exit\n",
    "final_prediction_entry = 0.5*global_prediction_entry+0.5*local_prediction_entry\n",
    "# final_prediction_entry[0] = local_prediction_entry[0]\n",
    "\n",
    "truth = np.concatenate([truth_exit, truth_entry])\n",
    "final_prediction = np.concatenate([final_prediction_exit, final_prediction_entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Result as Datadrame and csv\n",
    "\n",
    "tollgate_id = [1,3,1,2,3]  #exit first, then entry\n",
    "direction_id = [1,1,0,0,0]  #exit first, then entry\n",
    "\n",
    "date=['2016-10-18','2016-10-19','2016-10-20','2016-10-21','2016-10-22','2016-10-23','2016-10-24']\n",
    "\n",
    "time_start_v1=['08:00:00','08:20:00','08:40:00','09:00:00','09:20:00','09:40:00']\n",
    "time_start_v2=['17:00:00','17:20:00','17:40:00','18:00:00','18:20:00','18:40:00']\n",
    "time_end_v1=['08:20:00','08:40:00','09:00:00','09:20:00','09:40:00','10:00:00']\n",
    "time_end_v2=['17:20:00','17:40:00','18:00:00','18:20:00','18:40:00','19:00:00']\n",
    "\n",
    "final = []\n",
    "\n",
    "for i in range(0,len(final_prediction)):\n",
    "    for j in range(0,len(final_prediction[0])):\n",
    "        for k in range(0,len(final_prediction[0][0])):\n",
    "            if j%2==0:\n",
    "                final.append({\n",
    "                    'tollgate_id':tollgate_id[i],\n",
    "                    'time_window': \"[\"+date[j//2]+\" \"+time_start_v1[k%6]+\",\"+date[j//2]+\" \"+time_end_v1[k%6]+\")\",\n",
    "                    'direction':direction_id[i],\n",
    "                    'volume':final_prediction[i][j][k]\n",
    "                })\n",
    "            elif j%2==1:\n",
    "                final.append({\n",
    "                    'tollgate_id':tollgate_id[i],\n",
    "                    'time_window': \"[\"+date[j//2]+\" \"+time_start_v2[k%6]+\",\"+date[j//2]+\" \"+time_end_v2[k%6]+\")\",\n",
    "                    'direction':direction_id[i],\n",
    "                    'volume':final_prediction[i][j][k]\n",
    "                })\n",
    "df_result = pd.DataFrame(final)\n",
    "df_result.to_csv(\"proj_group03_result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
